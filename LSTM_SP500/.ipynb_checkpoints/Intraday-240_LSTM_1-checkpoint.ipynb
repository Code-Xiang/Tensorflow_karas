{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = 'models-Intraday-240-1-LSTM'\n",
    "result_folder = 'results-Intraday-240-1-LSTM'\n",
    "for directory in [model_folder,result_folder]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "SP500_df = pd.read_csv('data/SPXconst_2020_new.csv')\n",
    "all_companies = list(set(SP500_df.values.flatten()))\n",
    "all_companies.remove(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituents = {'-'.join(col.split('/')[::-1]):set(SP500_df[col].dropna()) \n",
    "                for col in SP500_df.columns}\n",
    "constituents_train = {} \n",
    "for test_year in range(1993,2016):\n",
    "    months = [str(t)+'-0'+str(m) if m<10 else str(t)+'-'+str(m) \n",
    "              for t in range(test_year-3,test_year) for m in range(1,13)]\n",
    "    constituents_train[test_year] = [list(constituents[m]) for m in months]\n",
    "    constituents_train[test_year] = set([i for sublist in constituents_train[test_year] \n",
    "                                         for i in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label(df_open,df_close,perc=[0.5,0.5]):\n",
    "    if not np.all(df_close.iloc[:,0]==df_open.iloc[:,0]):\n",
    "        print('Date Index issue')\n",
    "        return\n",
    "    perc = [0.]+list(np.cumsum(perc))\n",
    "    label = (df_close.iloc[:,1:]/df_open.iloc[:,1:]-1).apply(\n",
    "            lambda x: pd.qcut(x.rank(method='first'),perc,labels=False), axis=1)\n",
    "    return label[1:]\n",
    "def create_stock_data(df_open,df_close,st,m=240):\n",
    "    st_data = pd.DataFrame([])\n",
    "    st_data['Date'] = list(df_close['Date'])\n",
    "    st_data['Name'] = [st]*len(st_data)\n",
    "    daily_change = df_close[st]/df_open[st]-1\n",
    "    for k in range(m)[::-1]:\n",
    "        st_data['IntraR'+str(k)] = daily_change.shift(k)\n",
    "\n",
    "    st_data['IntraR-future'] = daily_change.shift(-1)  # 将后一天赋值给当前的日期  \n",
    "    st_data['label'] = list(label[st])+[np.nan] #最后一个加一个nan\n",
    "    st_data['Month'] = list(df_close['Date'].str[:-3]) # 去掉后面的天，留月份\n",
    "    st_data = st_data.dropna()\n",
    "    \n",
    "    trade_year = st_data['Month'].str[:4] # 取年份\n",
    "    st_data = st_data.drop(columns=['Month'])\n",
    "    st_train_data = st_data[trade_year<str(test_year)] # 交易年份小于测试年份的都是训练年份\n",
    "    st_test_data = st_data[trade_year==str(test_year)] # 交易年份是测试年份的则是测试年份\n",
    "    return np.array(st_train_data),np.array(st_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>CSCO</th>\n",
       "      <th>UAL</th>\n",
       "      <th>TROW</th>\n",
       "      <th>ISRG</th>\n",
       "      <th>NVR</th>\n",
       "      <th>TPR</th>\n",
       "      <th>DVN</th>\n",
       "      <th>CE</th>\n",
       "      <th>...</th>\n",
       "      <th>CRM</th>\n",
       "      <th>PGR</th>\n",
       "      <th>WAT</th>\n",
       "      <th>IEX</th>\n",
       "      <th>BWA</th>\n",
       "      <th>LRCX</th>\n",
       "      <th>NWL</th>\n",
       "      <th>UAA</th>\n",
       "      <th>BLK</th>\n",
       "      <th>PPL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-01-02</td>\n",
       "      <td>0.251798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.921079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.824210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.564747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.177134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.524198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.844329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990-01-03</td>\n",
       "      <td>0.271442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.936560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.944816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.570284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.209388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.856481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.860459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990-01-04</td>\n",
       "      <td>0.273228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.944300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.824211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.568438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.177133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.882043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.849706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990-01-05</td>\n",
       "      <td>0.269656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.952040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.065421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.568438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.112624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.830923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.833574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990-01-08</td>\n",
       "      <td>0.267870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.959780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.944816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.568437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.080372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.805360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.812066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>1993-12-27</td>\n",
       "      <td>0.206849</td>\n",
       "      <td>1.255515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.954947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.712947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.785410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.531662</td>\n",
       "      <td>2.283227</td>\n",
       "      <td>8.793470</td>\n",
       "      <td>8.962267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.017184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>1993-12-28</td>\n",
       "      <td>0.214302</td>\n",
       "      <td>1.250494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.954947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.125000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.930897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.768187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.547788</td>\n",
       "      <td>2.395150</td>\n",
       "      <td>8.941261</td>\n",
       "      <td>8.907456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.017184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>1993-12-29</td>\n",
       "      <td>0.218030</td>\n",
       "      <td>1.265560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.921241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.125000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.018077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.791150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.596169</td>\n",
       "      <td>2.395151</td>\n",
       "      <td>8.941261</td>\n",
       "      <td>8.880045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.031089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>1993-12-30</td>\n",
       "      <td>0.212439</td>\n",
       "      <td>1.285648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.954947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.125000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.105260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.819853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.580043</td>\n",
       "      <td>2.439920</td>\n",
       "      <td>9.015156</td>\n",
       "      <td>8.770417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.031090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>1993-12-31</td>\n",
       "      <td>0.221757</td>\n",
       "      <td>1.315780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.954947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.974490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.819854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.644549</td>\n",
       "      <td>2.417535</td>\n",
       "      <td>9.310732</td>\n",
       "      <td>8.880044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.003282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1013 rows × 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date      AAPL      CSCO  UAL      TROW  ISRG       NVR  TPR  \\\n",
       "0     1990-01-02  0.251798       NaN  NaN  0.921079   NaN  4.824210  NaN   \n",
       "1     1990-01-03  0.271442       NaN  NaN  0.936560   NaN  4.944816  NaN   \n",
       "2     1990-01-04  0.273228       NaN  NaN  0.944300   NaN  4.824211  NaN   \n",
       "3     1990-01-05  0.269656       NaN  NaN  0.952040   NaN  5.065421  NaN   \n",
       "4     1990-01-08  0.267870       NaN  NaN  0.959780   NaN  4.944816  NaN   \n",
       "...          ...       ...       ...  ...       ...   ...       ...  ...   \n",
       "1008  1993-12-27  0.206849  1.255515  NaN  1.954947   NaN  9.250000  NaN   \n",
       "1009  1993-12-28  0.214302  1.250494  NaN  1.954947   NaN  9.125000  NaN   \n",
       "1010  1993-12-29  0.218030  1.265560  NaN  1.921241   NaN  9.125000  NaN   \n",
       "1011  1993-12-30  0.212439  1.285648  NaN  1.954947   NaN  9.125000  NaN   \n",
       "1012  1993-12-31  0.221757  1.315780  NaN  1.954947   NaN  9.750000  NaN   \n",
       "\n",
       "           DVN  CE  ...  CRM       PGR  WAT       IEX       BWA      LRCX  \\\n",
       "0          NaN NaN  ...  NaN  0.564747  NaN  2.177134       NaN       NaN   \n",
       "1          NaN NaN  ...  NaN  0.570284  NaN  2.209388       NaN       NaN   \n",
       "2          NaN NaN  ...  NaN  0.568438  NaN  2.177133       NaN       NaN   \n",
       "3          NaN NaN  ...  NaN  0.568438  NaN  2.112624       NaN       NaN   \n",
       "4          NaN NaN  ...  NaN  0.568437  NaN  2.080372       NaN       NaN   \n",
       "...        ...  ..  ...  ...       ...  ...       ...       ...       ...   \n",
       "1008  6.712947 NaN  ...  NaN  1.785410  NaN  4.531662  2.283227  8.793470   \n",
       "1009  6.930897 NaN  ...  NaN  1.768187  NaN  4.547788  2.395150  8.941261   \n",
       "1010  7.018077 NaN  ...  NaN  1.791150  NaN  4.596169  2.395151  8.941261   \n",
       "1011  7.105260 NaN  ...  NaN  1.819853  NaN  4.580043  2.439920  9.015156   \n",
       "1012  6.974490 NaN  ...  NaN  1.819854  NaN  4.644549  2.417535  9.310732   \n",
       "\n",
       "           NWL  UAA  BLK       PPL  \n",
       "0     4.524198  NaN  NaN  1.844329  \n",
       "1     4.856481  NaN  NaN  1.860459  \n",
       "2     4.882043  NaN  NaN  1.849706  \n",
       "3     4.830923  NaN  NaN  1.833574  \n",
       "4     4.805360  NaN  NaN  1.812066  \n",
       "...        ...  ...  ...       ...  \n",
       "1008  8.962267  NaN  NaN  3.017184  \n",
       "1009  8.907456  NaN  NaN  3.017184  \n",
       "1010  8.880045  NaN  NaN  3.031089  \n",
       "1011  8.770417  NaN  NaN  3.031090  \n",
       "1012  8.880044  NaN  NaN  3.003282  \n",
       "\n",
       "[1013 rows x 505 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_year = 1993\n",
    "# for test_year in range(1993,2020):\n",
    "#     print('-'*40)\n",
    "#     print(test_year)\n",
    "#     print('-'*40)\n",
    "filename = 'Open_Close/Open-'+str(test_year-3)+'.csv'\n",
    "df_open = pd.read_csv(filename)\n",
    "filename = 'Open_Close/Close-'+str(test_year-3)+'.csv'\n",
    "df_close = pd.read_csv(filename)\n",
    "colums = df_open.columns\n",
    "df_open[colums] = df_open[colums].replace(0,np.nan)\n",
    "df_open.loc[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = create_label(df_open,df_close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_names = sorted(list(constituents[str(test_year-1)+'-12']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = [],[]\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  from ipykernel import kernelapp as app\n",
      "D:\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  app.launch_new_instance()\n",
      "D:\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "D:\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    }
   ],
   "source": [
    "for st in stock_names:\n",
    "        st_train_data,st_test_data = create_stock_data(df_open,df_close,st)\n",
    "        train_data.append(st_train_data)\n",
    "        test_data.append(st_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31889580,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.concatenate([x for x in train_data])\n",
    "test_data = np.concatenate([x for x in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31889580,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32864\\4073712892.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRobustScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "scaler = RobustScaler()\n",
    "scaler.fit(train_data[:,2:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
